name: Deploy Databricks Bundle GenAI

on:
  workflow_dispatch:
    inputs:
      target:
        description: "Deployment target"
        required: true
        default: "dev"
        type: choice
        options:
          - dev
          - qa
          - prod
          
      run_job:
        description: "Run the job after deploy?"
        required: true
        default: "true"
        type: choice
        options: ["true", "false"]

jobs:
  deploy:
    runs-on: ubuntu-latest

    steps:
      # 1) Checkout repo
      - uses: actions/checkout@v4

      # 2) Setup Python (for Databricks CLI + jq)
      - name: Set up Python
        uses: actions/setup-python@v5
        with:
          python-version: "3.10"
          cache: "pip"
          cache-dependency-path: "requirements.txt"

      # 3) Install Python deps (optional for bundles)
      - name: Install Python dependencies
        run: |
          python -m pip install --upgrade pip
          pip install -r requirements.txt || true

      # 4) Install NEW Databricks CLI from GitHub releases
      - name: Install Databricks CLI (new)
        run: |
          set -euo pipefail
          sudo apt-get update -y
          sudo apt-get install -y jq unzip tar file

          # Get latest linux_amd64 asset URL (zip or tar.gz)
          ASSET_URL="$(curl -s https://api.github.com/repos/databricks/cli/releases/latest \
            | jq -r '.assets[] | select(.name | test("linux_amd64\\.(zip|tar\\.gz)$")) | .browser_download_url' | head -n1)"

          if [ -z "$ASSET_URL" ] || [ "$ASSET_URL" = "null" ]; then
            echo "❌ Could not determine Databricks CLI asset URL from GitHub Releases."
            exit 1
          fi
          echo "Downloading Databricks CLI from: $ASSET_URL"

          curl -L -o /tmp/databricks_cli_asset "$ASSET_URL"

          mkdir -p /tmp/dbc_extracted
          if [[ "$ASSET_URL" == *.zip ]]; then
            unzip -o /tmp/databricks_cli_asset -d /tmp/dbc_extracted
          else
            tar -xzf /tmp/databricks_cli_asset -C /tmp/dbc_extracted
          fi

          BIN_PATH="$(find /tmp/dbc_extracted -type f -name databricks | head -n1)"
          if [ -z "$BIN_PATH" ]; then
            echo "❌ Could not find 'databricks' binary in extracted assets."
            find /tmp/dbc_extracted -maxdepth 3 -type f -print
            exit 1
          fi

          mkdir -p "$HOME/.databricks/bin"
          cp "$BIN_PATH" "$HOME/.databricks/bin/databricks"
          chmod +x "$HOME/.databricks/bin/databricks"

          # Verify immediately
          "$HOME/.databricks/bin/databricks" version

          # Make available to subsequent steps
          echo "$HOME/.databricks/bin" >> $GITHUB_PATH

      # 5) Set environment from target
      - name: Set environment variables
        run: |
          echo "TARGET=${{ github.event.inputs.target }}" >> $GITHUB_ENV
          if [ "${{ github.event.inputs.target }}" = "dev" ]; then
            echo "DATABRICKS_HOST=${{ secrets.DATABRICKS_HOST_DEV }}"   >> $GITHUB_ENV
            echo "DATABRICKS_TOKEN=${{ secrets.DATABRICKS_TOKEN_DEV }}" >> $GITHUB_ENV
          elif [ "${{ github.event.inputs.target }}" = "qa" ]; then
            echo "DATABRICKS_HOST=${{ secrets.DATABRICKS_HOST_QA }}"    >> $GITHUB_ENV
            echo "DATABRICKS_TOKEN=${{ secrets.DATABRICKS_TOKEN_QA }}"  >> $GITHUB_ENV
          elif [ "${{ github.event.inputs.target }}" = "prod" ]; then
            echo "DATABRICKS_HOST=${{ secrets.DATABRICKS_HOST_PROD }}"  >> $GITHUB_ENV
            echo "DATABRICKS_TOKEN=${{ secrets.DATABRICKS_TOKEN_PROD }}" >> $GITHUB_ENV
          else
            echo "❌ Unknown target"; exit 1
          fi
      # 6.1) Convert ipynb → py
      - name: Convert ipynb → py
        run: |
          pip install jupyter
          jupyter nbconvert --to script notebooks/*.ipynb --output-dir notebooks/

          
      # 6.2) Validate bundle
      - name: Validate Databricks Bundle
        run: databricks bundle validate --target "$TARGET"

      # 7) Deploy bundle
      - name: Deploy Databricks Bundle
        run: databricks bundle deploy --target "$TARGET"

     # 8) Run the job and capture run id
      - name: Run Databricks Job
        run: |
          RUN_INFO=$(databricks bundle run etl_demo_job --target "$TARGET" -o json)
          echo "$RUN_INFO" > run_info.json
          echo "RUN_ID=$(jq -r '.run_id' run_info.json)" >> $GITHUB_ENV 

      # 9) Save run output/logs
      - name: Get Job Output
        run: |
          databricks runs get-output --run-id $RUN_ID > run_output.json
          cat run_output.json

      # 10) Summarize logs using GenAI
      - name: Summarize Logs with GenAI
        run: |
          SUMMARY=$(jq -r '. | tostring' run_output.json | \
            curl -s -X POST https://api.openai.com/v1/chat/completions \
              -H "Authorization: Bearer ${{ secrets.OPENAI_API_KEY }}" \
              -H "Content-Type: application/json" \
              -d '{
                "model": "gpt-4o-mini",
                "messages": [
                  {"role": "system", "content": "You are a DevOps assistant. Summarize Databricks job logs and suggest root cause fixes."},
                  {"role": "user", "content": "'"$(cat run_output.json | jq -c .)"'"}
                ]
              }' | jq -r '.choices[0].message.content')

          echo "$SUMMARY" > job_summary.txt
          cat job_summary.txt

      # 11) Generate release notes with GenAI
      - name: Generate Release Notes
        run: |
          NOTES=$(curl -s -X POST https://api.openai.com/v1/chat/completions \
              -H "Authorization: Bearer ${{ secrets.OPENAI_API_KEY }}" \
              -H "Content-Type: application/json" \
              -d '{
                "model": "gpt-4o-mini",
                "messages": [
                  {"role": "system", "content": "You are a release manager. Write concise release notes for a Databricks CI/CD deployment."},
                  {"role": "user", "content": "Deployment Target: $TARGET. Logs: '"$(cat run_output.json | jq -c .)"'"}
                ]
              }' | jq -r '.choices[0].message.content')

          echo "$NOTES" > release_notes.md
          cat release_notes.md

      # 12) Upload artifacts for client review
      - uses: actions/upload-artifact@v4
        with:
          name: deployment-artifacts
          path: |
            run_output.json
            job_summary.txt
            release_notes.md
